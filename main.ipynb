{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chess AI\n",
    "construct $f(p)$ as a 3 layer deep 2048 units wide artificial neural network\\\n",
    "for each move, $f(p) = \\max\\limits_{p\\rightarrow p_0} - f(p_0)$\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import chess\n",
    "import chess.pgn\n",
    "import time\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAMBDA = 0.01\n",
    "EPOCHS = 10\n",
    "KAPPA = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset\n",
    "1. Players will choose an optimal or near-optimal move. This means that for two position in succession \n",
    "$p \\rightarrow q$ observed in the game, we will have $f(p) = -f(q)$\n",
    "2. For the same reason above, going from $p$ not to $q$, but to a random position $r$, we must have $f(r) > f(q)$ because the random position is better for the next player and worse for the player that made the move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "chessGames = pandas.read_csv('chessgm.csv')\n",
    "# copy the \"pgn\" column to a pgn file\n",
    "f = open(\"chessGames.pgn\", \"w\")\n",
    "for pgn in chessGames['pgn']:\n",
    "    f.write(pgn + \"\\n\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "f = open(\"chessGames.pgn\", \"r\")\n",
    "piece_to_index = {\n",
    "    'P': 0,  'N': 1,  'B': 2,  'R': 3,  'Q': 4,  'K': 5,  # White pieces\n",
    "    'p': 6,  'n': 7,  'b': 8,  'r': 9,  'q': 10, 'k': 11,  # Black pieces\n",
    "}\n",
    "chess_data = []\n",
    "# board to vector(8*8*12) one-hot encoding\n",
    "def board2vec(board):\n",
    "    vec = torch.zeros((12, 8, 8), dtype=torch.float32).to(device)  # 调整维度顺序\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is not None:\n",
    "            vec[piece_to_index[piece.symbol()]][square // 8][square % 8] = 1\n",
    "    return vec\n",
    "\n",
    "while game:=chess.pgn.read_game(f):\n",
    "    chessBoard = game.board()\n",
    "    for move in game.mainline_moves():\n",
    "        legal_moves = list(chessBoard.legal_moves)\n",
    "        pseudo_move = random.choice(legal_moves)\n",
    "        chessBoard2 = chessBoard.copy()\n",
    "        chessBoard2.push(pseudo_move)\n",
    "        r = board2vec(chessBoard2)\n",
    "        p = board2vec(chessBoard)\n",
    "        chessBoard.push(move)\n",
    "        q = board2vec(chessBoard)\n",
    "        chess_data.append((p, q, r))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, data, device):\n",
    "        self.data = data\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, q, r = self.data[idx]\n",
    "        return p, q, r\n",
    "dataloader = ChessDataset(chess_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessValueNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessValueNetwork, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(12, 32, kernel_size=3, padding=1), # [12, 8, 8] -> [32, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # [32, 8, 8] -> [64, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2) # [64, 8, 8] -> [64, 4, 4]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 256), # [1, 64*4*4] -> [1, 256]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128), # [1, 256] -> [1, 128]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),  # 输出标量\n",
    "            nn.Tanh()  # 限制在 [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # 展平成 [Features]\n",
    "        x = x.view(-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# 目标函数定义\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def objective_function(model, p, q, r, kappa=10.0):\n",
    "    # Forward pass: Compute scores for p, q, and r\n",
    "    f_p = model(p).squeeze()  # Score for p\n",
    "    f_q = model(q).squeeze()  # Score for q\n",
    "    f_r = model(r).squeeze()  # Score for r\n",
    "    \n",
    "    # Loss components\n",
    "    # Loss A: Ensure f(q) > f(r) (optimal move vs random move)\n",
    "    loss_a = -torch.log(F.sigmoid(f_q - f_r)).mean()\n",
    "\n",
    "    # Loss B: Ensure f(p) + f(q) close to zero (soft equality constraint)\n",
    "    loss_b = -torch.log(F.sigmoid(kappa * (f_p + f_q))).mean()\n",
    "\n",
    "    # Loss C: Ensure -f(p) - f(q) close to zero (soft equality constraint)\n",
    "    loss_c = -torch.log(F.sigmoid(-kappa * (f_p + f_q))).mean()\n",
    "\n",
    "    # Total loss: Combine all components\n",
    "    total_loss = loss_a + loss_b + loss_c\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def lr_lambda(current_epoch):\n",
    "    current_time = time.time()  # 当前时间戳\n",
    "    elapsed_time = current_time - t0\n",
    "    return math.exp(-elapsed_time / 86400)\n",
    "\n",
    "model = ChessValueNetwork().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=LAMBDA)\n",
    "t0 =time.time()\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for p, q, r in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = objective_function(model, p, q, r, KAPPA).to(device)\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        optimizer.step()\n",
    "        scheduler.step()   \n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {total_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
