{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chess AI\n",
    "construct $f(p)$ as a 3 layer deep 2048 units wide artificial neural network\\\n",
    "for each move, $f(p) = \\max\\limits_{p\\rightarrow p_0} - f(p_0)$\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chess\n",
    "import chess.pgn\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import logging\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "mp.set_start_method(\"spawn\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(filename='myapp.log', level=logging.INFO)\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.DEBUG) \n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "console_handler.setFormatter(formatter)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAMBDA = 10\n",
    "EPOCHS = 10\n",
    "KAPPA = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset\n",
    "1. Players will choose an optimal or near-optimal move. This means that for two position in succession \n",
    "$p \\rightarrow q$ observed in the game, we will have $f(p) = -f(q)$\n",
    "2. For the same reason above, going from $p$ not to $q$, but to a random position $r$, we must have $f(r) > f(q)$ because the random position is better for the next player and worse for the player that made the move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dimitrioskourtikakis/gm-games-chesscom\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "chessGames = pandas.read_csv(path+\"/GM_games_dataset.csv\", chunksize=1000)\n",
    "# copy the \"pgn\" column to a pgn file\n",
    "for i, chunk in enumerate(tqdm(chessGames)):\n",
    "    with open(f\"./data/chessGame{i}.pgn\", \"w\") as f:\n",
    "        for pgn in chunk['pgn']:\n",
    "            f.write(pgn + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chessModel import ChessDataset, ChessValueNetwork, objective_function, piece_to_index\n",
    "\n",
    "def lr_lambda(current_epoch):\n",
    "    current_time = time.time()  # 当前时间戳\n",
    "    elapsed_time = current_time - t0\n",
    "    return math.exp(-elapsed_time / 86400)\n",
    "\n",
    "model = ChessValueNetwork().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "t0 = time.time()\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"1.82.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 10:02:24,184 - __main__ - INFO - creating dataset for test data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m test_pgn \u001b[38;5;241m=\u001b[39m pgn_files[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     84\u001b[0m pgn_files\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpgn_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pgn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKAPPA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [6], line 22\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, optimizer, scheduler, objective_function, pgn_files, test_pgn, device, EPOCHS, KAPPA, logger)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(model, optimizer, scheduler, objective_function, pgn_files, test_pgn, device, EPOCHS, KAPPA, logger):\n\u001b[0;32m     21\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreating dataset for test data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m     test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mChessDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_pgn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m     24\u001b[0m     best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\Documents\\chessai\\chessModel.py:38\u001b[0m, in \u001b[0;36mChessDataset.__init__\u001b[1;34m(self, pgn_file, device)\u001b[0m\n\u001b[0;32m     36\u001b[0m pseudo_move \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(legal_moves)\n\u001b[0;32m     37\u001b[0m board\u001b[38;5;241m.\u001b[39mpush(pseudo_move)\n\u001b[1;32m---> 38\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboard2vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m board\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m     40\u001b[0m board\u001b[38;5;241m.\u001b[39mpush(move)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\Documents\\chessai\\chessModel.py:63\u001b[0m, in \u001b[0;36mChessDataset.board2vec\u001b[1;34m(self, board, flip)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 piece_index \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m  \n\u001b[0;32m     62\u001b[0m         vec[piece_index, row, col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 63\u001b[0m vec \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vec\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def board2vec(board, flip=False):\n",
    "        vec = np.zeros((12, 8, 8), dtype=np.float32)\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece is not None:\n",
    "                piece_index = piece_to_index[piece.symbol()]\n",
    "                row, col = divmod(square, 8)\n",
    "                if flip:\n",
    "                    # 翻转行\n",
    "                    row = 7 - row\n",
    "                    # 翻转棋子颜色\n",
    "                    if piece_index < 6:  \n",
    "                        piece_index += 6 \n",
    "                    else: \n",
    "                        piece_index -= 6  \n",
    "                vec[piece_index, row, col] = 1\n",
    "        vec = torch.tensor(vec, dtype=torch.float32)\n",
    "        return vec\n",
    "# 训练代码\n",
    "def train_model(model, optimizer, scheduler, objective_function, pgn_files, test_pgn, device, EPOCHS, KAPPA, logger):\n",
    "    logger.info(\"creating dataset for test data\")\n",
    "    test_dataset = ChessDataset(test_pgn, device=device)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "    best_loss = float(\"inf\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        try:\n",
    "            for pgn_file in pgn_files:\n",
    "                model.train()\n",
    "                # 为每个PGN文件创建数据集和数据加载器\n",
    "                logger.info(\"creating dataset for \" + pgn_file)\n",
    "                chess_dataset = ChessDataset(pgn_file, device=device)\n",
    "                dataloader = DataLoader(chess_dataset, batch_size=64)\n",
    "                \n",
    "                for batch_idx, (p, q, r) in enumerate(dataloader):\n",
    "                    p, q, r = p.to(device), q.to(device), r.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = objective_function(model, p, q, r, KAPPA)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss += loss.item()\n",
    "                    if batch_idx % 1000 == 0:\n",
    "                        logger.info(f\"Epoch [{epoch+1}/{EPOCHS}], PGN File [{pgn_file}], Batch [{batch_idx}], Loss: {loss.item():.4f}, lr: {scheduler.get_last_lr()[0]}\")\n",
    "                        \n",
    "                model.eval()\n",
    "                test_loss = 0\n",
    "                for batch_idx, (p, q, r) in enumerate(test_dataloader):\n",
    "                    p, q, r = p.to(device), q.to(device), r.to(device)\n",
    "                    loss = objective_function(model, p, q, r, KAPPA)\n",
    "                    test_loss += loss.item()\n",
    "                logger.info(\"test loss:\" + str(test_loss/len(test_dataloader)))\n",
    "                if test_loss < best_loss:\n",
    "                    torch.save(model.state_dict(), str(round(test_loss, 2))+\".pth\")\n",
    "                    logger.info(\"New best loss, saving model to\" + str(round(test_loss, 2))+\".pth\")\n",
    "                    best_loss = test_loss\n",
    "                scheduler.step()\n",
    "                # checkmate 1-0\n",
    "                board = chess.Board(\"rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq e3 0 1\")\n",
    "                vec = board2vec(board).to(device)\n",
    "                vec = vec.unsqueeze(0)\n",
    "                logger.info(\"1-0\")\n",
    "                logger.info(model(vec))\n",
    "                # black 5.0\n",
    "                board = chess.Board(\"rnb1q3/pppp1kpp/8/6b1/8/8/PPPP1PPP/RNB1K2R w KQ - 0 10\")\n",
    "                vec = board2vec(board).to(device)\n",
    "                vec = vec.unsqueeze(0)\n",
    "                logger.info(\"0-1\")\n",
    "                logger.info(model(vec))\n",
    "                del chess_dataset, dataloader, p, q, r\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred: {e}\")\n",
    "        \n",
    "        logger.info(f\"Epoch [{epoch+1}/{EPOCHS}], Total Loss: {total_loss:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pgn_files = []\n",
    "    for root, dirs, files in os.walk('./data'):\n",
    "        for file in files:\n",
    "            pgn_files.append(\"./data/\" + file)\n",
    "    random.shuffle(pgn_files)\n",
    "    test_pgn = pgn_files[-1]\n",
    "    pgn_files.pop(-1)\n",
    "    train_model(model, optimizer, scheduler, objective_function, pgn_files, test_pgn, device, EPOCHS, KAPPA, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgn_file = \"./data/chessGame0.pgn\"\n",
    "logger.info(\"creating dataset for \" + pgn_file)\n",
    "chess_dataset = ChessDataset(pgn_file, device=device)\n",
    "dataloader = DataLoader(chess_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "model.train()\n",
    "for batch_idx, (p, q, r) in enumerate(dataloader):\n",
    "    p, q, r = p.to(device), q.to(device), r.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = objective_function(model, p, q, r, KAPPA)\n",
    "    loss.backward()\n",
    "    # 梯度裁剪\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    if batch_idx % 1000 == 0:\n",
    "        logger.info(f\"PGN File [{pgn_file}], Batch [{batch_idx}], Loss: {loss.item():.4f}, lr: {scheduler.get_last_lr()[0]}\")\n",
    "        logger.info(model(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3145]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = chess.Board(\"2k5/p6p/1p6/5p2/1b6/3n4/K7/8 b - - 17 38\")\n",
    "vec = board2vec(board, flip=True).to(device)\n",
    "vec = vec.unsqueeze(0)\n",
    "model(vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
