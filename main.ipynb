{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chess AI\n",
    "construct $f(p)$ as a 3 layer deep 2048 units wide artificial neural network\\\n",
    "for each move, $f(p) = \\max\\limits_{p\\rightarrow p_0} - f(p_0)$\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import chess\n",
    "import chess.pgn\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAMBDA = 0.01\n",
    "EPOCHS = 10\n",
    "KAPPA = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset\n",
    "1. Players will choose an optimal or near-optimal move. This means that for two position in succession \n",
    "$p \\rightarrow q$ observed in the game, we will have $f(p) = -f(q)$\n",
    "2. For the same reason above, going from $p$ not to $q$, but to a random position $r$, we must have $f(r) > f(q)$ because the random position is better for the next player and worse for the player that made the move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/dimitrioskourtikakis/gm-games-chesscom/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dimitrioskourtikakis/gm-games-chesscom\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/tqdm/std.py:1181: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for obj in iterable:\n",
      "/root/miniconda3/lib/python3.12/site-packages/tqdm/std.py:1181: DtypeWarning: Columns (2,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for obj in iterable:\n",
      "5it [00:17,  3.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# copy the \"pgn\" column to a pgn file\u001b[39;00m\n\u001b[1;32m      4\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchessGames.pgn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchessGames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpgn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpgn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpgn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1843\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1985\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[0;32m-> 1985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "chessGames = pandas.read_csv(\"dataset.csv\", chunksize=100000)\n",
    "# copy the \"pgn\" column to a pgn file\n",
    "f = open(\"chessGames.pgn\", \"w\")\n",
    "for chunk in tqdm(chessGames):\n",
    "    for pgn in chunk['pgn']:\n",
    "        f.write(pgn + \"\\n\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "piece_to_index = {\n",
    "    'P': 0,  'N': 1,  'B': 2,  'R': 3,  'Q': 4,  'K': 5,  # White pieces\n",
    "    'p': 6,  'n': 7,  'b': 8,  'r': 9,  'q': 10, 'k': 11,  # Black pieces\n",
    "}\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, games, device):\n",
    "        self.games = games\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.games)\n",
    "        \n",
    "    def board2vec(board):\n",
    "        vec = torch.zeros((12, 8, 8), dtype=torch.float32).to(device)  # 调整维度顺序\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece is not None:\n",
    "                vec[piece_to_index[piece.symbol()]][square // 8][square % 8] = 1\n",
    "        return vec\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Find the game and move index corresponding to idx\n",
    "        current_idx = 0\n",
    "        for game in self.games:\n",
    "            moves = list(game.mainline_moves())\n",
    "            if current_idx + len(moves) > idx:\n",
    "                move_idx = idx - current_idx\n",
    "                chessBoard = game.board()\n",
    "\n",
    "                # Play up to the move_idx\n",
    "                for move in moves[:move_idx]:\n",
    "                    chessBoard.push(move)\n",
    "\n",
    "                # Generate p, q, and r\n",
    "                p = self.board2vec(chessBoard)\n",
    "                legal_moves = list(chessBoard.legal_moves)\n",
    "                pseudo_move = random.choice(legal_moves)\n",
    "                chessBoard2 = chessBoard.copy()\n",
    "                chessBoard2.push(pseudo_move)\n",
    "                r = self.board2vec(chessBoard2)\n",
    "                chessBoard.push(moves[move_idx])\n",
    "                q = self.board2vec(chessBoard)\n",
    "                return p, q, r\n",
    "            current_idx += len(moves)\n",
    "        raise IndexError(\"Index out of range\")\n",
    "        \n",
    "with open(\"chessGames.pgn\") as f:\n",
    "    games = list()\n",
    "    while game:=chess.pgn.read_game(f):\n",
    "        games.append(game)\n",
    "\n",
    "dataloader = ChessDataset(games, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessValueNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessValueNetwork, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(12, 32, kernel_size=3, padding=1), # [12, 8, 8] -> [32, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # [32, 8, 8] -> [64, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2) # [64, 8, 8] -> [64, 4, 4]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 256), # [1, 64*4*4] -> [1, 256]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128), # [1, 256] -> [1, 128]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),  # 输出标量\n",
    "            nn.Tanh()  # 限制在 [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # 展平成 [Features]\n",
    "        x = x.view(-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# 目标函数定义\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def objective_function(model, p, q, r, kappa=10.0):\n",
    "    # Forward pass: Compute scores for p, q, and r\n",
    "    f_p = model(p).squeeze()  # Score for p\n",
    "    f_q = model(q).squeeze()  # Score for q\n",
    "    f_r = model(r).squeeze()  # Score for r\n",
    "    \n",
    "    # Loss components\n",
    "    # Loss A: Ensure f(q) > f(r) (optimal move vs random move)\n",
    "    loss_a = -torch.log(F.sigmoid(f_q - f_r)).mean()\n",
    "\n",
    "    # Loss B: Ensure f(p) + f(q) close to zero (soft equality constraint)\n",
    "    loss_b = -torch.log(F.sigmoid(kappa * (f_p + f_q))).mean()\n",
    "\n",
    "    # Loss C: Ensure -f(p) - f(q) close to zero (soft equality constraint)\n",
    "    loss_c = -torch.log(F.sigmoid(-kappa * (f_p + f_q))).mean()\n",
    "\n",
    "    # Total loss: Combine all components\n",
    "    total_loss = loss_a + loss_b + loss_c\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def lr_lambda(current_epoch):\n",
    "    current_time = time.time()  # 当前时间戳\n",
    "    elapsed_time = current_time - t0\n",
    "    return math.exp(-elapsed_time / 86400)\n",
    "\n",
    "model = ChessValueNetwork().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=LAMBDA)\n",
    "t0 =time.time()\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for p, q, r in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = objective_function(model, p, q, r, KAPPA).to(device)\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        optimizer.step()\n",
    "        scheduler.step()   \n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {total_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
